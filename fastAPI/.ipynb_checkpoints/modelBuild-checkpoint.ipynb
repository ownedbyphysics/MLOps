{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv(\"language_detection_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hvis 6 mol dihydrogen (brint) reagerer fuldstæ...</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Essa evolução na física ganhou ares de uma rev...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'intero sistema per la misurazione, il tratta...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estes se tornaram uma grande dor de cabeça com...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entretanto, o Modelo Padrão não é capaz de des...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Language\n",
       "0  Hvis 6 mol dihydrogen (brint) reagerer fuldstæ...       da\n",
       "1  Essa evolução na física ganhou ares de uma rev...       pt\n",
       "2  L'intero sistema per la misurazione, il tratta...       it\n",
       "3  Estes se tornaram uma grande dor de cabeça com...       pt\n",
       "4  Entretanto, o Modelo Padrão não é capaz de des...       pt"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pt    1883\n",
       "en    1732\n",
       "ar    1187\n",
       "es    1152\n",
       "da     996\n",
       "fr     923\n",
       "tr     880\n",
       "ml     788\n",
       "sv     760\n",
       "it     701\n",
       "ru     658\n",
       "ta     537\n",
       "nl     509\n",
       "el     482\n",
       "hi     130\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value count for each language\n",
    "data[\"Language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data[\"Language\"])\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[\"Sentence\"], y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[!@#$(),\\n\"%^*?\\:;~`0-9]', ' ', text)\n",
    "    text = re.sub(r'[[]]', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "x_train = x_train.apply(preprocess_text)\n",
    "x_test = x_test.apply(preprocess_text)\n",
    "\n",
    "# Define the pipeline: TF-IDF + Naïve Bayes\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  # Step 1: TF-IDF transformation\n",
    "    ('model', MultinomialNB())     # Step 2: Train the Naïve Bayes model\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9688438438438438\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is :\",ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       242\n",
      "           1       0.98      0.91      0.94       220\n",
      "           2       1.00      0.94      0.97        80\n",
      "           3       0.97      0.99      0.98       336\n",
      "           4       1.00      0.90      0.95       221\n",
      "           5       1.00      0.97      0.98       192\n",
      "           6       1.00      1.00      1.00        17\n",
      "           7       1.00      0.96      0.98       147\n",
      "           8       1.00      0.99      0.99       140\n",
      "           9       1.00      0.94      0.97       105\n",
      "          10       0.98      0.99      0.99       390\n",
      "          11       0.67      0.99      0.80       136\n",
      "          12       0.98      0.98      0.98       156\n",
      "          13       1.00      0.99      1.00       108\n",
      "          14       1.00      0.96      0.98       174\n",
      "\n",
      "    accuracy                           0.97      2664\n",
      "   macro avg       0.97      0.97      0.97      2664\n",
      "weighted avg       0.97      0.97      0.97      2664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)  # `le` is your fitted LabelEncoder\n",
    "\n",
    "with open(\"pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pipeline.pkl\", \"rb\") as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the loaded pipeline\n",
    "new_sentences = [\"This is a test sentence.\", \"Ceci est une phrase en français.\"]\n",
    "predictions = loaded_pipeline.predict(new_sentences)\n",
    "\n",
    "print(predictions)  # Output: Language labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'fr'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_predictions = le.inverse_transform(predictions)\n",
    "decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
